{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e2abdc",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c596363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe1642",
   "metadata": {},
   "source": [
    "# 0. Bigram Model (Chapter 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17e13f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bigram:\n",
    "    def __init__(self):\n",
    "        # Pseudowords\n",
    "        self.pseudo_init = '<s>'; self.pseudo_termin = '</s>'\n",
    "        self.corpus_sequence = []\n",
    "        self.token_count = {self.pseudo_init:0, self.pseudo_termin:0}\n",
    "        self.bigram_count = {self.pseudo_init:{self.pseudo_init:0, self.pseudo_termin:0}, \n",
    "                             self.pseudo_termin:{self.pseudo_init:0, self.pseudo_termin:0}}\n",
    "\n",
    "    \"\"\" \n",
    "        Preprocessing\n",
    "            - preprocess any paragraph into a sequence of tokens\n",
    "    \"\"\"\n",
    "    def preprocess_corpus(self, paragraph):\n",
    "        corpus_sequence = []\n",
    "        for sentence in (paragraph.split('.')): # Divide by sentences\n",
    "            if (sentence == '') : corpus_sequence.append(self.pseudo_termin); break # Ignore the void sentence after the last period\n",
    "            corpus_sequence.append(self.pseudo_init) # Add a pseudo_init before every sentence.\n",
    "            for word in ((sentence.strip()).split(' ')): # Remove spaces and divide by words\n",
    "                corpus_sequence.append(word) # Add all word to the sequence\n",
    "            corpus_sequence.append(self.pseudo_termin) # Add a pseudo_termin after every sentence\n",
    "        return corpus_sequence[:-1] # In case the given paragraph doesn't end with a full sentence\n",
    "    \n",
    "    def preprocess_target(self, target):\n",
    "        target_sequence = []\n",
    "        for token in target.split(' '):\n",
    "            target_sequence.append(token)\n",
    "        return target_sequence\n",
    "                \n",
    "                \n",
    "            \n",
    "    \"\"\"\n",
    "        Construct Bigram Count\n",
    "            - from the corpus sequence, construct bigram count table\n",
    "            - self.corpus_sequence should have been constructed in advance\n",
    "    \"\"\"\n",
    "    def count_bigram(self):\n",
    "        prev_token = self.pseudo_init; self.token_count[self.pseudo_init] += 1;\n",
    "        for token in self.corpus_sequence[1:]:\n",
    "            if token in self.token_count:\n",
    "                self.token_count[token] += 1\n",
    "            else: \n",
    "                self.token_count[token] = 1\n",
    "                # Add a new row(of token) to the bigram_count graph\n",
    "                self.bigram_count[token] = {token:0}\n",
    "                for existing_token in self.bigram_count.keys():\n",
    "                    self.bigram_count[token][existing_token] = 0\n",
    "                    # Add a new column to the bigram_count graph\n",
    "                    self.bigram_count[existing_token][token] = 0\n",
    "            self.bigram_count[prev_token][token] += 1\n",
    "            prev_token = token\n",
    "    \n",
    "    def display_bigram_count(self):\n",
    "        display(pd.DataFrame(self.bigram_count).transpose())\n",
    "    \n",
    "    def train(self, corpus, show_table=False):\n",
    "        self.corpus_sequence = self.preprocess_corpus(corpus)\n",
    "        self.count_bigram()\n",
    "        if (show_table == True):\n",
    "            self.display_bigram_count()\n",
    "    \n",
    "    def calculate_bigram(self, target):\n",
    "        # 1. Input Processing\n",
    "        target_sequence = self.preprocess_target(target)\n",
    "        \n",
    "        # 2. Bigram Count\n",
    "        #V = len(self.token_count.keys()) # Number of tokens (including pseudowords)\n",
    "        \n",
    "        n = len(target_sequence)\n",
    "        \n",
    "        p_total = 1\n",
    "        for k in range(1,n):\n",
    "            w_k = target_sequence[k]; w_kminus1 = target_sequence[k-1]\n",
    "            p_k_given_kminus1 = self.bigram_count[w_kminus1][w_k] / self.token_count[w_kminus1]\n",
    "            p_total *= p_k_given_kminus1\n",
    "        \n",
    "        return p_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2786efd",
   "metadata": {},
   "source": [
    "## 0.1 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a92a90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <th>I</th>\n",
       "      <th>am</th>\n",
       "      <th>Sam</th>\n",
       "      <th>do</th>\n",
       "      <th>not</th>\n",
       "      <th>like</th>\n",
       "      <th>green</th>\n",
       "      <th>eggs</th>\n",
       "      <th>and</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sam</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eggs</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       <s>  </s>  I  am  Sam  do  not  like  green  eggs  and  ham\n",
       "<s>      0     0  2   0    1   0    0     0      0     0    0    0\n",
       "</s>     2     0  0   0    0   0    0     0      0     0    0    0\n",
       "I        0     0  0   2    0   1    0     0      0     0    0    0\n",
       "am       0     1  0   0    1   0    0     0      0     0    0    0\n",
       "Sam      0     1  1   0    0   0    0     0      0     0    0    0\n",
       "do       0     0  0   0    0   0    1     0      0     0    0    0\n",
       "not      0     0  0   0    0   0    0     1      0     0    0    0\n",
       "like     0     0  0   0    0   0    0     0      1     0    0    0\n",
       "green    0     0  0   0    0   0    0     0      0     1    0    0\n",
       "eggs     0     0  0   0    0   0    0     0      0     0    1    0\n",
       "and      0     0  0   0    0   0    0     0      0     0    0    1\n",
       "ham      0     1  0   0    0   0    0     0      0     0    0    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus = \"I am Sam. Sam I am. I do not like green eggs and ham.\"\n",
    "\n",
    "bigram_model = Bigram()\n",
    "bigram_model.train(corpus, show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2b4d4",
   "metadata": {},
   "source": [
    "## 0.2 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c12871e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(I|<s>) = 0.67\n",
      "P(Sam|<s>) = 0.33\n",
      "P(am|I) = 0.67\n",
      "P(</s>|Sam) = 0.5\n",
      "P(Sam|am) = 0.5\n",
      "P(do|I) = 0.33\n"
     ]
    }
   ],
   "source": [
    "targets = [\"<s> I\", \"<s> Sam\", \"I am\",\n",
    "           \"Sam </s>\", \"am Sam\", \"I do\"]\n",
    "\n",
    "for target in targets:\n",
    "    print(\"P(\" + target.split()[-1] + \"|\" + target.split()[0] + \") = \" + str(round(bigram_model.calculate_bigram(target),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a1a310",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08553fbc",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57a07f5",
   "metadata": {},
   "source": [
    "# 1. Naive Bayes Classifier (Chapter 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4726ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        import pandas as pd; import numpy as np; import math\n",
    "        self.classes = set(); self.features = set()\n",
    "        self.class_cnt = {}; self.feature_cnt = {}\n",
    "        self.data_cnt = None; self.X_shape = None;\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self._count(X_train, y_train)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        # 0. Validate Input\n",
    "        if (X_test.shape[1:] != self.X_shape):\n",
    "            raise Exception(\"Match the data size of X_test\")\n",
    "        y_predict = []\n",
    "        for X in X_test:\n",
    "            y_predict.append(self._predict_single(X))\n",
    "        return y_predict\n",
    "    \n",
    "    def _predict_single(self, X):\n",
    "        probability = {}\n",
    "        for label in self.classes:\n",
    "            probability[label] = self._log_probability(X, label)\n",
    "        return max(probability, key=probability.get)\n",
    "    \n",
    "    \"\"\"\n",
    "        Count the number of..\n",
    "        \n",
    "        1. Classes throughout the whole dataset\n",
    "            - update self.class_cnt\n",
    "        \n",
    "        2. Feature occurence per class\n",
    "            - update self.feature_cnt\n",
    "    \"\"\"\n",
    "    def _count(self, X_train, y_train):\n",
    "        # 0. Validate Input\n",
    "        self.data_cnt = len(y_train);\n",
    "        if (len(X_train) != self.data_cnt): \n",
    "            raise Exception(\"Match the data size of X_train and y_train\")\n",
    "        else:\n",
    "            self.X_shape = X_train.shape[1:]\n",
    "        \n",
    "        for i in range(self.data_cnt):\n",
    "            X = X_train[i]; y = y_train[i]\n",
    "            \n",
    "            ### [Update Class Count] ###################################################\n",
    "            \n",
    "            # 1. Check if a new class appears\n",
    "            if (y not in self.classes):\n",
    "                # 1.1 Add the class to class set and self.class_cnt\n",
    "                self.classes.add(y) \n",
    "                self.class_cnt[y] = 0\n",
    "                # 1.2 Create a column for the class in count table\n",
    "                self.feature_cnt[y] = dict(zip(list(self.features), np.zeros(len(self.features), dtype=int))) \n",
    "            \n",
    "            # 2. Update the class count\n",
    "            self.class_cnt[y] += 1\n",
    "            \n",
    "            ############################################################################\n",
    "            \n",
    "            ### [Update Feature Count] #################################################\n",
    "            \n",
    "            for x_i in X:\n",
    "                # 1. Check if a new feature appears\n",
    "                if (x_i not in self.features):\n",
    "                    # 1.1 Add the feature to the feature set\n",
    "                    self.features.add(x_i)\n",
    "                    # 1.2 Add a row for the feature in count table\n",
    "                    for _class in self.feature_cnt.keys():\n",
    "                        self.feature_cnt[_class][x_i] = 0\n",
    "                        \n",
    "                # 2. Update the feature count\n",
    "                self.feature_cnt[y][x_i] += 1\n",
    "            \n",
    "            ############################################################################\n",
    "        return\n",
    "    \n",
    "    \"\"\"\n",
    "        Compute P(X|y)\n",
    "        \n",
    "        1. term1: P(y)\n",
    "        2. term2: P(X|y) -> with Laplace Smoothing\n",
    "            \n",
    "    \"\"\"\n",
    "    def _log_probability(self, X, y):\n",
    "        term1 = math.log(self.class_cnt[y] / self.data_cnt, 10)\n",
    "        \n",
    "        term2 = 0\n",
    "        features_sum = sum(self.feature_cnt[y].values()) + len(self.features)\n",
    "        for x_i in X:\n",
    "            try:\n",
    "                term2 += math.log(self.feature_cnt[y][x_i] + 1, 10)\n",
    "            except:\n",
    "                term2 = 0\n",
    "        \n",
    "        return term1 + term2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c6410c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[\"A\", \"B\", \"C\"], [\"A\", \"B\", \"B\"], [\"D\", \"F\", \"A\"], [\"C\", \"B\", \"B\"]])\n",
    "y_train = np.array([\"Pass\", \"Pass\", \"Fail\", \"Fail\"])\n",
    "\n",
    "X_test1 = np.array([[\"A\", \"C\", \"B\"],\n",
    "                    [\"A\", \"C\", \"X\"],  # Unseen data -> smoothed by Laplace\n",
    "                    [\"F\", \"D\", \"B\"],\n",
    "                    [\"X\", \"Y\", \"Z\"]]) # Unseen data -> smoothed by Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "19b68324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pass', 'Fail', 'Fail', 'Fail']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = NaiveBayes()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "classifier.predict(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a5bc6",
   "metadata": {},
   "source": [
    "# 2. Softmax Regression Classifier (Chapter 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7fe92a",
   "metadata": {},
   "source": [
    "## 2.1 Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "caf8469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionBase(object):\n",
    "    def __init__(self):\n",
    "        import numpy as np;\n",
    "        self.n_labels = None\n",
    "        self.X_size = None\n",
    "        self.weights = None; self.biases = None\n",
    "    \n",
    "    \"\"\"\n",
    "        Training Data\n",
    "            - y_train: An array of one-hot encoded vectors\n",
    "            - lr: learning rate\n",
    "    \"\"\"\n",
    "    def fit(self, X_train, y_train, lr=0.1):\n",
    "        # 0. Validate input\n",
    "        if (len(X_train) != len(y_train)): raise Exception(\"Match the data shape of X_train and y_train\")\n",
    "        self.X_size = len(X_train[0])\n",
    "        self.n_labels = len(y_train[0])\n",
    "        \n",
    "        # 1. Assign random weights/biases\n",
    "        std=1e-4 # standard deviation\n",
    "        self.weights = std * np.random.randn(self.n_labels, self.X_size) # an array whose size is (n_features, n_classes)\n",
    "        self.biases = std * np.random.randn(self.n_labels) # an array of length n_classes\n",
    "        \n",
    "        # 2. Update\n",
    "        for i in range(len(y_train)): # loop over the train data\n",
    "            loss, w_jacobian, b_jacobian = self.softmax_loss(X_train[i], y_train[i])\n",
    "            self.gradient_descent(w_jacobian, b_jacobian, lr)\n",
    "            print(\"Epoch \" + str(i) + \"\\a:\\a (loss: \" + str(loss) + \")\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # 0. Validate input\n",
    "        if (X.shape[0] != self.X_size): raise Exception(\"Match data shape of X_test: \" + str(self.X_size))\n",
    "        \n",
    "        # 1. Predict Label(class)\n",
    "        prob = np.dot(self.weights, X) + self.biases\n",
    "        label = np.argmax(prob)\n",
    "        \n",
    "        # 2. Convert the label into a one-hot encoded vector\n",
    "        label_vector = np.zeros(self.n_labels, dtype=int); label_vector[label] = 1\n",
    "        return label_vector\n",
    "        \n",
    "        \n",
    "        \n",
    "    def softmax_loss(self, X, y):\n",
    "        \"\"\"\n",
    "            Compute the Loss and Gradients for a binary classifier\n",
    "            Return:\n",
    "                - Loss\n",
    "                - Gradient\n",
    "        \"\"\"\n",
    "        # 1. Compute the summ for softmax\n",
    "        summ = 0\n",
    "        for k in range(self.n_labels): # loop through the classes\n",
    "            w_k = self.weights[k]; b_k = self.biases[k]\n",
    "            summ += np.exp(np.dot(w_k, X) + b_k)\n",
    "        \n",
    "        # 2. Update the gradient matrixes, and calculate the loss\n",
    "        loss = 0; \n",
    "        w_jacobian = np.zeros(self.weights.shape); b_jacobian = np.zeros(self.biases.shape)\n",
    "        for k in range(self.n_labels):\n",
    "            w_k = self.weights[k]; b_k = self.biases[k]\n",
    "            softmax = (np.dot(w_k, X) + b_k) / summ # softmax\n",
    "            gradient = softmax - y[k]\n",
    "            for i in range(self.X_size):\n",
    "                w_jacobian[k][i] = gradient * X[i]\n",
    "            b_jacobian[k] = gradient\n",
    "            \n",
    "            # Loss -= softmax for the correct class\n",
    "            if (y[k] == 1): loss -= softmax;\n",
    "        \n",
    "        return loss, w_jacobian, b_jacobian\n",
    "    \n",
    "    \n",
    "    def gradient_descent(self, w_jacobian, b_jacobian, lr):\n",
    "        \"\"\"\n",
    "            Update the weights and biases\n",
    "        \"\"\"\n",
    "        self.weights -= lr * w_jacobian\n",
    "        self.biases -= lr * b_jacobian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e9eafc",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13c55b",
   "metadata": {},
   "source": [
    "### 1) Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "b10d5d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train = []; y_train = []\n",
    "\n",
    "# Create random data points\n",
    "data_per_label = 50\n",
    "labels = [[0,0,1], [0,1,0], [1,0,0]]; centroids = [(2,2), (3,5), (5,2)]\n",
    "for i in range(len(labels)):\n",
    "    xs = centroids[i][0] + (np.random.random_sample((data_per_label,)) - 0.5) * 2\n",
    "    ys = centroids[i][1] + (np.random.random_sample((data_per_label,)) - 0.5) * 2\n",
    "    X_train += list(zip(xs, ys))\n",
    "    y_train += [labels[i] for j in range(data_per_label)]\n",
    "    \n",
    "# Shuffle\n",
    "shuffle = list(zip(X_train, y_train)); np.random.shuffle(shuffle)\n",
    "X_train = list(map(lambda pair: pair[0], shuffle))\n",
    "y_train = list(map(lambda pair: pair[1], shuffle))\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.scatter([point[0] for point in X_train], [point[1] for point in X_train], c=y_train, label=y_train)\n",
    "plt.xlim([0, 7]); plt.ylim([0, 7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f187eb",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "0e5edeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\u0007:\u0007 (loss: 4.4105381033849416e-05)\n",
      "Epoch 1\u0007:\u0007 (loss: -8.603652441817992e-06)\n",
      "Epoch 2\u0007:\u0007 (loss: -0.13534745400388967)\n",
      "Epoch 3\u0007:\u0007 (loss: -0.06861055854746033)\n",
      "Epoch 4\u0007:\u0007 (loss: -0.07971829758389916)\n",
      "Epoch 5\u0007:\u0007 (loss: -2.9189777685678223e-06)\n",
      "Epoch 6\u0007:\u0007 (loss: -0.03459009556946306)\n",
      "Epoch 7\u0007:\u0007 (loss: -0.017180303353278546)\n",
      "Epoch 8\u0007:\u0007 (loss: -0.07128848191833256)\n",
      "Epoch 9\u0007:\u0007 (loss: -0.0179826781406854)\n",
      "Epoch 10\u0007:\u0007 (loss: -0.03399923915081583)\n",
      "Epoch 11\u0007:\u0007 (loss: -9.484092690265957e-05)\n",
      "Epoch 12\u0007:\u0007 (loss: -0.04839570513651256)\n",
      "Epoch 13\u0007:\u0007 (loss: -0.00046250343662537167)\n",
      "Epoch 14\u0007:\u0007 (loss: -0.008528938719311902)\n",
      "Epoch 15\u0007:\u0007 (loss: -3.770801346369887e-05)\n",
      "Epoch 16\u0007:\u0007 (loss: -0.00024821714928577917)\n",
      "Epoch 17\u0007:\u0007 (loss: -3.930834379734031e-05)\n",
      "Epoch 18\u0007:\u0007 (loss: -3.507985530901265e-05)\n",
      "Epoch 19\u0007:\u0007 (loss: -0.0029505620379820857)\n",
      "Epoch 20\u0007:\u0007 (loss: -7.0383505651752735e-06)\n",
      "Epoch 21\u0007:\u0007 (loss: -0.000801224427279646)\n",
      "Epoch 22\u0007:\u0007 (loss: -1.2163065366065231e-06)\n",
      "Epoch 23\u0007:\u0007 (loss: -1.8692049855606934e-07)\n",
      "Epoch 24\u0007:\u0007 (loss: -0.0001894874459613982)\n",
      "Epoch 25\u0007:\u0007 (loss: -0.0002539223363646744)\n",
      "Epoch 26\u0007:\u0007 (loss: -2.6711796402830447e-06)\n",
      "Epoch 27\u0007:\u0007 (loss: -8.735745313055215e-06)\n",
      "Epoch 28\u0007:\u0007 (loss: -2.5425999052776663e-10)\n",
      "Epoch 29\u0007:\u0007 (loss: -1.293583258483294e-09)\n",
      "Epoch 30\u0007:\u0007 (loss: -6.511887705741016e-12)\n",
      "Epoch 31\u0007:\u0007 (loss: -8.155496775562204e-15)\n",
      "Epoch 32\u0007:\u0007 (loss: -1.7204441996257644e-14)\n",
      "Epoch 33\u0007:\u0007 (loss: -2.6075965690906803e-15)\n",
      "Epoch 34\u0007:\u0007 (loss: -4.8118691895037025e-17)\n",
      "Epoch 35\u0007:\u0007 (loss: -4.823593084621406e-19)\n",
      "Epoch 36\u0007:\u0007 (loss: -4.9458676345176516e-17)\n",
      "Epoch 37\u0007:\u0007 (loss: -2.5571041491004062e-20)\n",
      "Epoch 38\u0007:\u0007 (loss: -2.0744171576641073e-24)\n",
      "Epoch 39\u0007:\u0007 (loss: -5.2829849524338046e-17)\n",
      "Epoch 40\u0007:\u0007 (loss: -4.8074477592210035e-11)\n",
      "Epoch 41\u0007:\u0007 (loss: -2.5964932918629226e-20)\n",
      "Epoch 42\u0007:\u0007 (loss: -4.471727719717696e-21)\n",
      "Epoch 43\u0007:\u0007 (loss: -3.53211755521817e-28)\n",
      "Epoch 44\u0007:\u0007 (loss: -4.290760476199953e-22)\n",
      "Epoch 45\u0007:\u0007 (loss: -5.802422041496076e-26)\n",
      "Epoch 46\u0007:\u0007 (loss: -9.598535335775751e-11)\n",
      "Epoch 47\u0007:\u0007 (loss: -1.3583631991267403e-14)\n",
      "Epoch 48\u0007:\u0007 (loss: -1.550878605467899e-21)\n",
      "Epoch 49\u0007:\u0007 (loss: -8.962655981769372e-16)\n",
      "Epoch 50\u0007:\u0007 (loss: -4.008938893110516e-18)\n",
      "Epoch 51\u0007:\u0007 (loss: -9.37366528025325e-17)\n",
      "Epoch 52\u0007:\u0007 (loss: -1.2612877645835801e-20)\n",
      "Epoch 53\u0007:\u0007 (loss: -2.9043825521044006e-30)\n",
      "Epoch 54\u0007:\u0007 (loss: -6.96403966645963e-23)\n",
      "Epoch 55\u0007:\u0007 (loss: -4.190210169823115e-20)\n",
      "Epoch 56\u0007:\u0007 (loss: -1.7064838042250657e-12)\n",
      "Epoch 57\u0007:\u0007 (loss: -1.525719610290364e-17)\n",
      "Epoch 58\u0007:\u0007 (loss: -2.0914515344800388e-18)\n",
      "Epoch 59\u0007:\u0007 (loss: -1.398246353840177e-28)\n",
      "Epoch 60\u0007:\u0007 (loss: -5.5496776223505725e-22)\n",
      "Epoch 61\u0007:\u0007 (loss: -1.146921108306832e-14)\n",
      "Epoch 62\u0007:\u0007 (loss: -7.41757710540365e-33)\n",
      "Epoch 63\u0007:\u0007 (loss: -2.5956159664911467e-34)\n",
      "Epoch 64\u0007:\u0007 (loss: -1.1765722883358001e-21)\n",
      "Epoch 65\u0007:\u0007 (loss: -1.4012071537538974e-34)\n",
      "Epoch 66\u0007:\u0007 (loss: -4.1145742208595865e-22)\n",
      "Epoch 67\u0007:\u0007 (loss: -5.403992759632918e-15)\n",
      "Epoch 68\u0007:\u0007 (loss: -9.363696248084078e-18)\n",
      "Epoch 69\u0007:\u0007 (loss: -4.0380688413746216e-26)\n",
      "Epoch 70\u0007:\u0007 (loss: -4.838372278537902e-39)\n",
      "Epoch 71\u0007:\u0007 (loss: -4.619862289024623e-18)\n",
      "Epoch 72\u0007:\u0007 (loss: -9.141530276676241e-28)\n",
      "Epoch 73\u0007:\u0007 (loss: -2.647242808552348e-31)\n",
      "Epoch 74\u0007:\u0007 (loss: -4.441577943611662e-33)\n",
      "Epoch 75\u0007:\u0007 (loss: -1.857547282038415e-41)\n",
      "Epoch 76\u0007:\u0007 (loss: -2.035454842882579e-32)\n",
      "Epoch 77\u0007:\u0007 (loss: -1.2312790410314396e-33)\n",
      "Epoch 78\u0007:\u0007 (loss: -2.371743831204091e-22)\n",
      "Epoch 79\u0007:\u0007 (loss: -1.4638333158086963e-39)\n",
      "Epoch 80\u0007:\u0007 (loss: -2.826848231363789e-41)\n",
      "Epoch 81\u0007:\u0007 (loss: -5.48125944428644e-41)\n",
      "Epoch 82\u0007:\u0007 (loss: -1.0788361842170398e-14)\n",
      "Epoch 83\u0007:\u0007 (loss: -4.1627975353079464e-30)\n",
      "Epoch 84\u0007:\u0007 (loss: -7.691693897931212e-16)\n",
      "Epoch 85\u0007:\u0007 (loss: -2.5259249826073078e-37)\n",
      "Epoch 86\u0007:\u0007 (loss: -2.9515596831868267e-47)\n",
      "Epoch 87\u0007:\u0007 (loss: -2.4063672826376666e-18)\n",
      "Epoch 88\u0007:\u0007 (loss: -2.6723908969069224e-46)\n",
      "Epoch 89\u0007:\u0007 (loss: -1.1702427300728967e-30)\n",
      "Epoch 90\u0007:\u0007 (loss: -9.192736060507806e-36)\n",
      "Epoch 91\u0007:\u0007 (loss: -3.818160041989426e-39)\n",
      "Epoch 92\u0007:\u0007 (loss: -4.9089655790587123e-14)\n",
      "Epoch 93\u0007:\u0007 (loss: -4.959247274221949e-50)\n",
      "Epoch 94\u0007:\u0007 (loss: -2.77504826681315e-38)\n",
      "Epoch 95\u0007:\u0007 (loss: -1.5267668649208212e-26)\n",
      "Epoch 96\u0007:\u0007 (loss: -5.027657763802549e-41)\n",
      "Epoch 97\u0007:\u0007 (loss: -7.418472373837464e-27)\n",
      "Epoch 98\u0007:\u0007 (loss: -1.1155297863919122e-50)\n",
      "Epoch 99\u0007:\u0007 (loss: -9.654960292216078e-28)\n",
      "Epoch 100\u0007:\u0007 (loss: -2.6356873550731283e-52)\n",
      "Epoch 101\u0007:\u0007 (loss: -4.0554527531473725e-36)\n",
      "Epoch 102\u0007:\u0007 (loss: -4.967922501964993e-30)\n",
      "Epoch 103\u0007:\u0007 (loss: -2.1911034501035583e-46)\n",
      "Epoch 104\u0007:\u0007 (loss: -3.812401949237928e-34)\n",
      "Epoch 105\u0007:\u0007 (loss: -6.023636789740007e-47)\n",
      "Epoch 106\u0007:\u0007 (loss: -1.9694354019907466e-39)\n",
      "Epoch 107\u0007:\u0007 (loss: -3.760797939604462e-57)\n",
      "Epoch 108\u0007:\u0007 (loss: -1.2884343685340678e-47)\n",
      "Epoch 109\u0007:\u0007 (loss: -8.061689801774446e-59)\n",
      "Epoch 110\u0007:\u0007 (loss: -9.287557869341106e-31)\n",
      "Epoch 111\u0007:\u0007 (loss: -1.6154088726659115e-50)\n",
      "Epoch 112\u0007:\u0007 (loss: -7.258947990116815e-31)\n",
      "Epoch 113\u0007:\u0007 (loss: -3.968367109462628e-21)\n",
      "Epoch 114\u0007:\u0007 (loss: -8.947047382467926e-38)\n",
      "Epoch 115\u0007:\u0007 (loss: -2.136010526819606e-68)\n",
      "Epoch 116\u0007:\u0007 (loss: -5.6165583018001774e-65)\n",
      "Epoch 117\u0007:\u0007 (loss: -3.0049200267777075e-50)\n",
      "Epoch 118\u0007:\u0007 (loss: -9.362912147082786e-61)\n",
      "Epoch 119\u0007:\u0007 (loss: -2.004578628514908e-49)\n",
      "Epoch 120\u0007:\u0007 (loss: -5.177807135905522e-56)\n",
      "Epoch 121\u0007:\u0007 (loss: -1.3155133905086038e-59)\n",
      "Epoch 122\u0007:\u0007 (loss: -8.909483755344119e-25)\n",
      "Epoch 123\u0007:\u0007 (loss: -3.0439496673533296e-33)\n",
      "Epoch 124\u0007:\u0007 (loss: -3.3261657012884816e-58)\n",
      "Epoch 125\u0007:\u0007 (loss: -5.511930627738833e-59)\n",
      "Epoch 126\u0007:\u0007 (loss: -8.669527644825825e-63)\n",
      "Epoch 127\u0007:\u0007 (loss: -2.649853220789604e-43)\n",
      "Epoch 128\u0007:\u0007 (loss: -2.2820599097650402e-65)\n",
      "Epoch 129\u0007:\u0007 (loss: -1.692076705235191e-52)\n",
      "Epoch 130\u0007:\u0007 (loss: -4.107693141823549e-72)\n",
      "Epoch 131\u0007:\u0007 (loss: -3.4136898854555013e-72)\n",
      "Epoch 132\u0007:\u0007 (loss: -1.8207715304596996e-29)\n",
      "Epoch 133\u0007:\u0007 (loss: -1.1032959286556701e-37)\n",
      "Epoch 134\u0007:\u0007 (loss: -3.865846126814438e-52)\n",
      "Epoch 135\u0007:\u0007 (loss: -1.6128959217139016e-30)\n",
      "Epoch 136\u0007:\u0007 (loss: -1.279012733138532e-46)\n",
      "Epoch 137\u0007:\u0007 (loss: -2.4359296112562094e-47)\n",
      "Epoch 138\u0007:\u0007 (loss: -9.692324131391238e-70)\n",
      "Epoch 139\u0007:\u0007 (loss: -1.165058573805824e-24)\n",
      "Epoch 140\u0007:\u0007 (loss: -1.9728211769757973e-25)\n",
      "Epoch 141\u0007:\u0007 (loss: -8.231875364705705e-54)\n",
      "Epoch 142\u0007:\u0007 (loss: -2.988070190225373e-70)\n",
      "Epoch 143\u0007:\u0007 (loss: -8.595680772036946e-51)\n",
      "Epoch 144\u0007:\u0007 (loss: -6.6285609675324e-41)\n",
      "Epoch 145\u0007:\u0007 (loss: -2.7273431061903203e-72)\n",
      "Epoch 146\u0007:\u0007 (loss: -2.1076093514681462e-47)\n",
      "Epoch 147\u0007:\u0007 (loss: -8.974712569764864e-45)\n",
      "Epoch 148\u0007:\u0007 (loss: -1.7653654391153623e-39)\n",
      "Epoch 149\u0007:\u0007 (loss: -3.648142191006887e-27)\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegressionBase()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdda1e0",
   "metadata": {},
   "source": [
    "## 2.2 Minibatch + Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ac70d",
   "metadata": {},
   "source": [
    "- prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "a3b6f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(LogisticRegressionBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c484d7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NLP] *",
   "language": "python",
   "name": "conda-env-NLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
